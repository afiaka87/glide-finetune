# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md
image: clip-guided-diffusion

build:
  # set to true if your model requires a GPU
  gpu: true

  # a list of ubuntu apt packages to install
  system_packages:
    - "libgl1-mesa-glx"
    - "libglib2.0-0"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.8"

  # a list of packages in the format <package-name>==<version>
  python_packages:
     - "torch==1.8.0"
     - "torchvision==0.9.0"
     - "clip-anytorch==2.2"
     - "ftfy==6.0"
     - "idna==3.2"
     - "kornia==0.5"
     - "lpips==0.1.4"
     - "numpy==1.21"
     - "Pillow==8.3"
     - "packaging==21.0"
     - "protobuf==3.17"
     - "requests==2.26"
     - "tqdm==4.62"
     - "typing-extensions==3.10.0.2"
     - "urllib3==1.26"
     - "wandb==0.12"

  run:
    -  mkdir -p ~/.cache/clip/
    -  mkdir -p ~/.cache/clip-guided-diffusion/
    -  wget 'https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt' --output-document ~/.cache/clip/ViT-B-32.pt
    -  wget 'https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt' --output-document ~/.cache/clip-guided-diffusion/256x256_diffusion_uncond.pt
    -  git clone https://github.com/afiaka87/clip-guided-diffusion --single-branch --branch main --depth 1
    -  python3 clip-guided-diffusion/setup.py install
    -  git clone https://github.com/crowsonkb/guided-diffusion --single-branch --branch main --depth 1
    -  python3 -m pip install -e guided-diffusion
    # -  wget https://the-eye.eu/public/AI/models/512x512_diffusion_unconditional_ImageNet/512x512_diffusion_uncond_finetune_008100.pt --output-document ~/.cache/clip-guided-diffusion/512x512_diffusion_uncond_finetune_008100.pt
    # - curl -O -L -C - 'https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion.pt' > ~/.cache/clip-guided-diffusion/256x256_diffusion.pt
    # - curl -O -L -C - 'https://openaipublic.blob.core.windows.net/diffusion/jul-2021/512x512_diffusion.pt' > ~/.cache/clip-guided-diffusion/512x512_diffusion.pt
    # predict.py defines how predictions are run on your model
predict: "cog_predict.py:ClipGuidedDiffusionPredictor"